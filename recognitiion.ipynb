{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.weight', 'encoder.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "c:\\Users\\aswin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aswin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'morning'}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "image_path = \"C:/Users/aswin/OneDrive/Desktop/Work/IBM/air_canvas.png\"\n",
    "# Create the image-to-text pipeline using the TrOCR model\n",
    "pipe = pipeline(\"image-to-text\", model=\"microsoft/trocr-base-handwritten\")\n",
    "prediction = pipe(image_path)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "c:\\Users\\aswin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\donut\\feature_extraction_donut.py:28: FutureWarning: The class DonutFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use DonutImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "image_path = \"air_canvas.png\"\n",
    "pipe = pipeline(\"image-to-text\", model=\"jinhybr/OCR-Donut-CORD\")\n",
    "prediction = pipe(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '<s_cord-v2><s_menu><s_nm> Deliee</s_nm><s_price> Aswisr</s_nm><s_price> Aswisr</s_nm><s_price>'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'life ood,\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:/Program Files/Tesseract-OCR/tesseract.exe\"\n",
    "img_path = cv2.imread('C:/Users/aswin/OneDrive/Desktop/Work/IBM/air_canvas1.png')\n",
    "img = cv2.cvtColor(img_path, cv2.COLOR_BGR2GRAY)\n",
    "pytesseract.image_to_string(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text block orientation: Horizontal\n",
      "Slant angle of the entire text region: -0.28 degrees\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image  # For potential deskewing (slant correction)\n",
    "def get_slant(gray):\n",
    "  # Calculate moments\n",
    "  moments = cv2.moments(gray)\n",
    "  mu02 = moments['mu02']\n",
    "  mu11 = moments['mu11']\n",
    "  # Check for division by zero\n",
    "  if abs(mu02) < 1e-6:\n",
    "    return 0\n",
    "  else:\n",
    "    # Calculate slant angle (radians)\n",
    "    return np.degrees(np.arctan((2 * mu11) / mu02))\n",
    "\n",
    "\n",
    "def get_text_block_orientation(gray):\n",
    "  # Apply thresholding and find contours\n",
    "  thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "  cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "  \n",
    "  # Check for detected contours\n",
    "  if len(cnts) == 0:\n",
    "    return \"Text not detected\"\n",
    "  \n",
    "  # Get bounding rectangle of all contours\n",
    "  x, y, w, h = cv2.boundingRect(np.vstack(cnts))\n",
    "  \n",
    "  # Calculate aspect ratio\n",
    "  aspect_ratio = w / float(h)\n",
    "  \n",
    "  # Estimate orientation based on aspect ratio (heuristic)\n",
    "  if aspect_ratio > 1:\n",
    "    orientation = \"Horizontal\"\n",
    "  else:\n",
    "    orientation = \"Vertical\"\n",
    "  \n",
    "  # Calculate slant angle\n",
    "  slant_angle = get_slant(gray[y:y+h, x:x+w])  # Apply slant calculation on the text region\n",
    "\n",
    "  return orientation, slant_angle\n",
    "\n",
    "img_path = 'C:/Users/aswin/OneDrive/Desktop/Work/IBM/air_canvas1.png'\n",
    "img = cv2.imread(img_path)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Analyze text region\n",
    "orientation, slant_angle = get_text_block_orientation(gray)\n",
    "\n",
    "print(f\"Text block orientation: {orientation}\")\n",
    "print(f\"Slant angle of the entire text region: {slant_angle:.2f} degrees\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
